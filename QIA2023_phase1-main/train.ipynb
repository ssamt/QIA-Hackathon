{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c808b4e-6c06-405f-a9ab-3176236d486b",
   "metadata": {
    "id": "9c808b4e-6c06-405f-a9ab-3176236d486b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1680323020614,
     "user_tz": -540,
     "elapsed": 9,
     "user": {
      "displayName": "김병권",
      "userId": "17299946839009927524"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "final = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Ij8y6lzAbVb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1680323060284,
     "user_tz": -540,
     "elapsed": 384,
     "user": {
      "displayName": "김병권",
      "userId": "17299946839009927524"
     }
    },
    "outputId": "98c29c25-f683-4715-8867-c1f0d138f020"
   },
   "id": "4Ij8y6lzAbVb",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "MBTI = ['IE', 'SN', 'TF', 'JP']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ffe3023f-3ac3-4a1a-b100-2151b077d2a1",
   "metadata": {
    "id": "ffe3023f-3ac3-4a1a-b100-2151b077d2a1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1680323021963,
     "user_tz": -540,
     "elapsed": 1355,
     "user": {
      "displayName": "김병권",
      "userId": "17299946839009927524"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       User_ID  Gender  Age  MBTI  Q_number  \\\n11515      240       0   40  ISTJ        44   \n11516      240       0   40  ISTJ        45   \n11517      240       0   40  ISTJ        46   \n11518      240       0   40  ISTJ        47   \n11519      240       0   40  ISTJ        48   \n\n                                                  Answer  \n11515  <그렇다> 저는 계획에 차질이 생기면 돌아가기 위해 노력을 합니다. 이유는 그 계획...  \n11516  <그렇다> 저는 예전의 실수를 후회할 때가 많습니다. 이유는 그만큼 나태하게 산 적...  \n11517  <아니다> 저는 인간의 존재와 삶의 이유에 대해 깊이 생각하지 않습니다. 이유는 이...  \n11518  <아니다> 저는 감정에 휘둘리는 편이 아닙니다. 이유는 감정을 감추고 밖으로 표현하...  \n11519  <아니다> 저는 상대방 잘못일 때 상대방의 체면을 살려주기 위해 노력하지 않습니다....  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>MBTI</th>\n      <th>Q_number</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11515</th>\n      <td>240</td>\n      <td>0</td>\n      <td>40</td>\n      <td>ISTJ</td>\n      <td>44</td>\n      <td>&lt;그렇다&gt; 저는 계획에 차질이 생기면 돌아가기 위해 노력을 합니다. 이유는 그 계획...</td>\n    </tr>\n    <tr>\n      <th>11516</th>\n      <td>240</td>\n      <td>0</td>\n      <td>40</td>\n      <td>ISTJ</td>\n      <td>45</td>\n      <td>&lt;그렇다&gt; 저는 예전의 실수를 후회할 때가 많습니다. 이유는 그만큼 나태하게 산 적...</td>\n    </tr>\n    <tr>\n      <th>11517</th>\n      <td>240</td>\n      <td>0</td>\n      <td>40</td>\n      <td>ISTJ</td>\n      <td>46</td>\n      <td>&lt;아니다&gt; 저는 인간의 존재와 삶의 이유에 대해 깊이 생각하지 않습니다. 이유는 이...</td>\n    </tr>\n    <tr>\n      <th>11518</th>\n      <td>240</td>\n      <td>0</td>\n      <td>40</td>\n      <td>ISTJ</td>\n      <td>47</td>\n      <td>&lt;아니다&gt; 저는 감정에 휘둘리는 편이 아닙니다. 이유는 감정을 감추고 밖으로 표현하...</td>\n    </tr>\n    <tr>\n      <th>11519</th>\n      <td>240</td>\n      <td>0</td>\n      <td>40</td>\n      <td>ISTJ</td>\n      <td>48</td>\n      <td>&lt;아니다&gt; 저는 상대방 잘못일 때 상대방의 체면을 살려주기 위해 노력하지 않습니다....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/hackathon_train.csv', encoding='cp949', index_col=0)\n",
    "df.index = range(len(df))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "      User_ID  Gender  Age  MBTI  Q_number Short_Answer  \\\n7195      240  female   30  ISTP        56          그렇다   \n7196      240  female   30  ISTP        57          아니다   \n7197      240  female   30  ISTP        58          아니다   \n7198      240  female   30  ISTP        59          아니다   \n7199      240  female   30  ISTP        60          그렇다   \n\n                                            Long_Answer  \n7195  거래처에 가격 조정 때문에 3군데를 가야 하는 상황이었는데 이야기 잘 통하는 곳 2...  \n7196      상대방과 논쟁을 불러드릴 주제에는 관심이 없습니다 괜히 싸움을 일으키기 싫습니다   \n7197         나에게 온 기회를 포기할 수 없다 양보를 하게 되면 나에게 기회는 없어지니깐  \n7198        마감 기한이 정해지면 그 일을 끝날 때까지 늦게까지 일을 하고 퇴근하곤 합니다  \n7199           일을 할 때는 항상 진행될 때 이외의 상황을 생각하여 대처할 준비를 한다  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>MBTI</th>\n      <th>Q_number</th>\n      <th>Short_Answer</th>\n      <th>Long_Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7195</th>\n      <td>240</td>\n      <td>female</td>\n      <td>30</td>\n      <td>ISTP</td>\n      <td>56</td>\n      <td>그렇다</td>\n      <td>거래처에 가격 조정 때문에 3군데를 가야 하는 상황이었는데 이야기 잘 통하는 곳 2...</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>240</td>\n      <td>female</td>\n      <td>30</td>\n      <td>ISTP</td>\n      <td>57</td>\n      <td>아니다</td>\n      <td>상대방과 논쟁을 불러드릴 주제에는 관심이 없습니다 괜히 싸움을 일으키기 싫습니다</td>\n    </tr>\n    <tr>\n      <th>7197</th>\n      <td>240</td>\n      <td>female</td>\n      <td>30</td>\n      <td>ISTP</td>\n      <td>58</td>\n      <td>아니다</td>\n      <td>나에게 온 기회를 포기할 수 없다 양보를 하게 되면 나에게 기회는 없어지니깐</td>\n    </tr>\n    <tr>\n      <th>7198</th>\n      <td>240</td>\n      <td>female</td>\n      <td>30</td>\n      <td>ISTP</td>\n      <td>59</td>\n      <td>아니다</td>\n      <td>마감 기한이 정해지면 그 일을 끝날 때까지 늦게까지 일을 하고 퇴근하곤 합니다</td>\n    </tr>\n    <tr>\n      <th>7199</th>\n      <td>240</td>\n      <td>female</td>\n      <td>30</td>\n      <td>ISTP</td>\n      <td>60</td>\n      <td>그렇다</td>\n      <td>일을 할 때는 항상 진행될 때 이외의 상황을 생각하여 대처할 준비를 한다</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_excel('../data2/train_data.xlsx', index_col=0)\n",
    "df2.index = range(len(df2))\n",
    "df2.tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "answer_map = {'그렇다':0, '그렇자':0,\n",
    "              '중립':1, '중랍':1, '중간':1, '보통':1, '중립/모르겠다': 1,\n",
    "              '어렵다':2, '아니다':2, '<아니다':2, '아니요':2, '아니오':2}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "#question_result = torch.load('question_embed.pt')\n",
    "#question_list = question_result[1].tolist()\n",
    "gender_map = {0:0, 1:3}\n",
    "age_map = {20:0, 30:1, 40:2}\n",
    "def attach(result, df, filenum):\n",
    "    result = result.tolist()\n",
    "    for i in range(len(result)):\n",
    "        extend_l = [0 for i in range(6)]\n",
    "        if filenum == 1:\n",
    "            extend_l[gender_map[df.Gender[i]]+age_map[df.Age[i]]] = 1\n",
    "        result[i].extend(extend_l)\n",
    "    return torch.tensor(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def split(tensor):\n",
    "    vector_len = tensor.shape[1]\n",
    "    tensor = torch.reshape(tensor, (240, 48, vector_len))\n",
    "    train = torch.reshape(tensor[:,:40,:], (240*40, vector_len))\n",
    "    test = torch.reshape(tensor[:,40:,:], (240*8, vector_len))\n",
    "    return train, test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d18849bd-b6a3-4cf1-b60c-f4bbec19a1f0",
   "metadata": {
    "id": "d18849bd-b6a3-4cf1-b60c-f4bbec19a1f0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1680323023076,
     "user_tz": -540,
     "elapsed": 1115,
     "user": {
      "displayName": "김병권",
      "userId": "17299946839009927524"
     }
    }
   },
   "outputs": [],
   "source": [
    "result = torch.load('roberta/tuned_embed.pt')[1][:11520,:]\n",
    "result_real = attach(result, df, 1).float()\n",
    "if not final:\n",
    "    train_result, test_result = split(result_real)\n",
    "#result1, result2 = result[:11520], result[11520:]\n",
    "#result_real = torch.cat((attach(result1, df, 1), attach(result2, df2, 2))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "962af7ad-e05d-452c-bc04-8f293bcffbcd",
   "metadata": {
    "id": "962af7ad-e05d-452c-bc04-8f293bcffbcd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1680323107752,
     "user_tz": -540,
     "elapsed": 252,
     "user": {
      "displayName": "김병권",
      "userId": "17299946839009927524"
     }
    }
   },
   "outputs": [],
   "source": [
    "def set_random(SEED=0):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "    \n",
    "def convert_mbti_to_label(mbti):\n",
    "    stand = 'ISTJ'  # [0, 0, 0, 0]\n",
    "    label = []\n",
    "    for i in range(len(stand)):\n",
    "        if stand[i] == mbti[i]:\n",
    "            label.append(0.0)\n",
    "        else:\n",
    "            label.append(1.0)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93b09c3f-a2a5-4182-87ad-168f09e92d58",
   "metadata": {
    "id": "93b09c3f-a2a5-4182-87ad-168f09e92d58",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1680323108567,
     "user_tz": -540,
     "elapsed": 4,
     "user": {
      "displayName": "김병권",
      "userId": "17299946839009927524"
     }
    }
   },
   "outputs": [],
   "source": [
    "def run(model, dl, optimizer, criterion, train=True):\n",
    "    model = model.to(device)\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    predict_list = []\n",
    "    answer_list = []\n",
    "    loss_all = 0\n",
    "\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        predict_list.append(output)\n",
    "        answer_list.append(y)\n",
    "        loss_all += loss.item()\n",
    "\n",
    "    predict = torch.cat(predict_list)\n",
    "    answer = torch.cat(answer_list)\n",
    "    auc = [roc_auc_score(answer[:,i].tolist(), predict[:,i].tolist()) for i in range(len(answer[0]))]\n",
    "    loss = loss_all / len(dl)\n",
    "\n",
    "    return loss, torch.tensor(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "#label = list(map(convert_mbti_to_label, df['MBTI'].tolist()+df2['MBTI'].tolist()))\n",
    "label = torch.tensor(list(map(convert_mbti_to_label, df['MBTI'])))\n",
    "ds = MyDataset(result_real, label)\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "if not final:\n",
    "    train_label, test_label = split(label)\n",
    "    train_ds = MyDataset(train_result, train_label)\n",
    "    test_ds = MyDataset(test_result, test_label)\n",
    "    train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([-0.3165, -0.0164, -0.4889,  ...,  0.0000,  1.0000,  0.0000]),\n tensor([-0.3467, -0.0257, -0.4330,  ...,  0.0000,  1.0000,  0.0000]))"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_real[0], result_real[41]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([-0.3165, -0.0164, -0.4889,  ...,  0.0000,  1.0000,  0.0000]),\n tensor([-0.3467, -0.0257, -0.4330,  ...,  0.0000,  1.0000,  0.0000]))"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result[0], test_result[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3224, -0.0817, -0.4712,  ...,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.2800, -0.0304, -0.4509,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.4031, -0.1483, -0.5109,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.3459, -0.0739, -0.3754,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [-0.3661, -0.2026, -0.5535,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.3497, -0.2075, -0.5054,  ...,  0.0000,  0.0000,  1.0000]]) tensor([[1., 1., 1., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dl:\n",
    "    print(x, y)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "55b9771c-e8bc-4e10-8b11-5ee146b2b179",
   "metadata": {
    "id": "55b9771c-e8bc-4e10-8b11-5ee146b2b179",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1680323147440,
     "user_tz": -540,
     "elapsed": 428,
     "user": {
      "displayName": "김병권",
      "userId": "17299946839009927524"
     }
    }
   },
   "outputs": [],
   "source": [
    "def main(folder='ckpt'):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(1024+6, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(512, 4),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    train_final = []\n",
    "    val_final = []\n",
    "    save_dir = f'./{folder}'\n",
    "    for epoch in tqdm.tqdm(range(500)):\n",
    "        if final:\n",
    "            run(model, dl, optimizer, criterion)\n",
    "            if epoch%50 == 50-1:\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                torch.save(model, f\"{save_dir}/epoch_{epoch}.pt\")\n",
    "        else:\n",
    "            train_loss, train_auc = run(model, train_dl, optimizer, criterion)\n",
    "            val_loss, val_auc = run(model, test_dl, optimizer, criterion, train=False)\n",
    "            #writer.add_scalars('AUC/Train', {MBTI[i]:train_auc[i] for i in range(len(MBTI))}, epoch)\n",
    "            #writer.add_scalars('AUC/Test', {MBTI[i]:val_auc[i] for i in range(len(MBTI))}, epoch)\n",
    "            writer.add_scalar('AUC/Train', torch.mean(train_auc), epoch)\n",
    "            writer.add_scalar('AUC/Test', torch.mean(val_auc), epoch)\n",
    "            writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "            writer.add_scalar('Loss/Test', val_loss, epoch)\n",
    "            train_final.append([train_loss, train_auc])\n",
    "            val_final.append([val_loss, val_auc])\n",
    "            if epoch%50 == 50-1:\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                torch.save(model, f\"{save_dir}/epoch_{epoch}.pt\")\n",
    "\n",
    "    return train_final, val_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5198f7f7-89b5-43a1-8184-4eb34919cb8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5198f7f7-89b5-43a1-8184-4eb34919cb8f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1680324417314,
     "user_tz": -540,
     "elapsed": 234454,
     "user": {
      "displayName": "김병권",
      "userId": "17299946839009927524"
     }
    },
    "outputId": "d2fb17b0-6971-4560-f579-09ea0ef60d6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 323/500 [18:08<09:56,  3.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[120], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m writer \u001B[38;5;241m=\u001B[39m SummaryWriter(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./tensorboard/test\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_number\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m set_random(\u001B[38;5;241m422\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mckpt/ckpt\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtest_number\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[119], line 22\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(folder)\u001B[0m\n\u001B[0;32m     20\u001B[0m         torch\u001B[38;5;241m.\u001B[39msave(model, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msave_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/epoch_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 22\u001B[0m     train_loss, train_auc \u001B[38;5;241m=\u001B[39m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m     val_loss, val_auc \u001B[38;5;241m=\u001B[39m run(model, test_dl, optimizer, criterion, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;66;03m#writer.add_scalars('AUC/Train', {MBTI[i]:train_auc[i] for i in range(len(MBTI))}, epoch)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;66;03m#writer.add_scalars('AUC/Test', {MBTI[i]:val_auc[i] for i in range(len(MBTI))}, epoch)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[114], line 18\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(model, dl, optimizer, criterion, train)\u001B[0m\n\u001B[0;32m     16\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     17\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 18\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m predict_list\u001B[38;5;241m.\u001B[39mappend(output)\n\u001B[0;32m     20\u001B[0m answer_list\u001B[38;5;241m.\u001B[39mappend(y)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adam.py:141\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    130\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    133\u001B[0m         group,\n\u001B[0;32m    134\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    138\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    139\u001B[0m         state_steps)\n\u001B[1;32m--> 141\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adam.py:281\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    279\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 281\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    287\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    288\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    289\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adam.py:391\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    389\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 391\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    393\u001B[0m param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train all\n",
    "test_number = 85\n",
    "if os.path.isdir(f'./tensorboard/test{test_number}'):\n",
    "    print('Tensorboard folder already occupied.')\n",
    "else:\n",
    "    writer = SummaryWriter(f'./tensorboard/test{test_number}/')\n",
    "    set_random(422)\n",
    "    result = main(f'ckpt/ckpt{test_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
